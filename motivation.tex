\section{Motivation}
\label{sec:motivation}

Suppose someone implemented a clever algorithm for
regular expression matching. 
We want to use this implementation, but we also want to play safe and
make sure it is largely bug free by subjecting it to extensive
testing---verification is deemed to expensive.
Such testing requires us to come up with test cases and
implement a test oracle.


A test case consists of a regular expression \code{r} and an input
string \code{s}. If \code{match} is the implementation of matching
and \code{matchOracle} is the test oracle, then
executing the test case means to execute \code{match r
  s} and check whether the result is correct by comparing it with
\code{matchOracle r s}. 

A popular way of conducting such a test is using the QuickCheck library
\cite{quickcheck}, which performs property-based random testing. Using
QuickCheck, we would write a random generator for regular expressions
and then use the random generator for strings to generate many inputs for a
generated regular expression.

However, this approach has a
catch. Depending on the language of the regular expression, the
probability that a random string is a member of the language can be
severely skewed. As an example, consider the language $L = (ab)^*$ over the
alphabet $\Sigma = \{a, b\}$. Although $L$ contains infinitely many
words, the probability that a random word of
length $n$ is an element of $L$ is
\begin{itemize}
\item $0$ if $n$ is odd and
\item $\frac{1}{2^n}$ if $n$ is even.
\end{itemize}
Thus, the probability $p_n$ that a random word of length less than or equal to
$n$ is an element of $L$ is very small:
\begin{align*}
  p_n &= \frac{\lfloor n/2 \rfloor}{2^{n+1} - 1}
        \le \frac{n}{2^{n+2} - 2}
\end{align*}
Hence, the probability of (uniformly) randomly
selecting a word in $L$ is zero in the limit.

Hence, there are two problems with testing the regular expression
matcher.
\begin{enumerate}
\item How do we know whether the test oracle is correct, short of
  verifying it?
\item How do we ensure that relevant test cases are generated, given
  that the probability of randomly picking a word in the language is
  $0$ or $1$ for many regular languages?\footnote{Exercise for the
    interested reader:
    \begin{enumerate}
    \item Come up with a regular language $R$ such that $P(w\in R)$ is
      different from $0$ or $1$.
    \item Given a proper fraction $m/n$ (that is $n>0$ and $0\le m\le
      n$) define a regular language $R$ such that $P (w\in R) = m/n$.
    \end{enumerate}
  }
\end{enumerate}


Wouldn't it be nice to have a systematic and obviously correct means
of generating words \textbf{inside} of $L$ and \textbf{outside} of
$L$? Such a generation algorithm would obviate the need for an oracle
and it would make sure that we can control the number of test inputs
in the language and in the language's complement.

In the follwing we will tackle a slightly more general question, namely generating
the language of a \emph{generalized regular expression}, 
which subsumes the purpose of generating positive and negative sample
words for testing.

\subsection{Brief Intermezzo on Formal Languages}
\label{sec:research-question}

\begin{figure}[tp]
  \begin{align*}
    r, s & &L(\_)=\quad &  &
                             \makebox[1em][l]{\code{data GRE sig}}\\
         & ::= \Rnull & \ltext{empty}
                        & \emptyset
                           &&\code{= Zero}\\
         & \mid \Rempty & \ltext{empty word}
                        & \{ \varepsilon \}
                           && \code{| One}\\
         & \mid (a \in \Sigma) & \ltext{singleton}
                        &  \{ a \}
                           && \code{| Atom sig} \\
         & \mid \Runion rs & \ltext{alternative}
                        &  L (r) \cup L (s)
                           && \code{| Or (GRE sig) (GRE sig)}\\
         & \mid \Rconcat rs & \ltext{concatenation}
                        &  L (r) \cdot L (s)
                           && \code{| Dot (GRE sig) (GRE sig)}\\
         & \mid \Rstar r & \ltext{Kleene star}
                        & (L (r))^* 
                           && \code{| Star (GRE sig)}\\
         & \mid \Rintersect rs & \ltext{intersection}
                        & L (r) \cap L (s)
                           && \code{| And (GRE sig) (GRE sig)}\\
         & \mid \Rcomplement r & \ltext{complement}
                        & \Sigma^* \setminus L (r)
                           && \code{| Not (GRE sig)}
  \end{align*}
  % \begin{align*}
  %   L (\Rnull) &= \emptyset\\
  %   L (\Rempty) &= \{ \varepsilon \} \\
  %   L (a) &= \{ a \} \\
  %   L (\Runion rs) &= L (r) \cup L (s) \\
  %   L (\Rconcat rs) &= L (r) \cdot L (s) \\
  %   L (\Rstar r) &= (L (r))^* \\
  %   L (\Rintersect rs) &= L (r) \cap L (s) \\
  %   L (\Rcomplement r) &= \Sigma^* \setminus L (r)
  % \end{align*}
  \caption{Generalized regular expressions}
  \label{fig:generalized-regular-expressions}
\end{figure}

As customary, we write $\Sigma^*$ for the set of finite words over
alphabet $\Sigma$, which is defined inductively as the smallest set
such that $\varepsilon \in
\Sigma^*$ and $\forall a\in\Sigma, \forall w\in\Sigma^*, aw \in \Sigma^*$.
The semantics of an expression, $L(r) \subseteq \Sigma^*$, is a set of
words, which is also defined in
Figure~\ref{fig:generalized-regular-expressions}. It relies on
standard definitions from the theory of formal languages. We write
$\varepsilon$ for the empty word and $u\cdot v$ for the concatenation
of words $u, v \in \Sigma^*$. We write $|u|$ for the length of word
$u$. Unless otherwise specified, we use $a, b, c, \dots$ to range over
$\Sigma$ and $u, v, w, \dots$ to range over $\Sigma^*$.

If $U, V \subseteq \Sigma^*$ are
languages, then their concatenation (or product) is defined as $U\cdot
V = \{ u\cdot v \mid u\in U, v\in V\}$. We sometimes write $u\cdot V$
as an abbreviation for the product $\{u\}\cdot V$ with a singleton
language. The Kleene closure of a
language $U\subseteq \Sigma^*$ is defined as $U^* =
\bigcup_{i=0}^\infty U^i$ where $U^0 = \{\varepsilon\}$ and $U^{i+i} =
U \cdot U^i$. 

A generalized regular expression
(Figure~\ref{fig:generalized-regular-expressions}) is an expression
built from the regular operators empty set, empty word, singleton word
consisting of a single letter $a$ chosen from a finite alphabet
$\Sigma$, alternative, concatenation, and Kleene star. In addition, it
may contain the operators intersection and complement. The extra
operators do not add extra descriptive power as regular languages are
closed under intersection and complement \cite{AhoHopcroftUllman}, but
generalized regular expressions can be much more concise. 



\subsection{Naive Approach}
\label{sec:naive-approach}

We start with a naive implementation of the mathematical definition in
Figure~\ref{fig:generalized-regular-expressions}. We define an
alphabet by a list of \code{Char}.  We represent words by elements of Haskell's
\code{Data.Text.Text} datatype, abbreviated to \code{T.Text}. We
represent a language as a lazy list of \code{Text}, as a language
can be an infinite set. There are two further restrictions.
\begin{enumerate}
\item The output of a generator should not contain repetitions
  because we would like to guarantee that test inputs are different
  from each others.
\item The output of a generator should not be partial because it would
  lead the test code to hang on a nonterminating input.
\end{enumerate}

\begin{lstlisting}
import Data.Text as T

type Alphabet = [Char]
type Lang = [T.Text]

generate :: Alphabet -> GRE Char -> Lang
generate sigma r = gen r
  where
    gen Zero = []
    gen One  = [T.empty]
    gen (Atom t) = [T.singleton t]
    gen (Or r s) = union (gen r) (gen s)
    gen (Dot r s) = concatenate (gen r) (gen s)
    gen (Star r) = star (gen r)
    gen (And r s) = intersect (gen r) (gen s)
    gen (Not r) = complement sigma (gen r)
\end{lstlisting}
\begin{figure}[tp]
\begin{lstlisting}
module Examples.Naive where
import qualified Data.Text as T

union :: Lang -> Lang -> Lang
union lx ly = lx ++ ly

concatenate :: Lang -> Lang -> Lang
concatenate lx ly = [T.append wx wy | wx <- lx, wy <- ly ]

intersect :: Lang -> Lang -> Lang
intersect lx ly = [wx | wx <- lx, wx `elem` ly ]

star :: Lang -> Lang
star lx = concat lxi
  where
    lxi = [T.empty] : map (concatenate lx) lxi

complement :: Alphabet -> Lang -> Lang
complement sigma lx =
  undefined
\end{lstlisting}
  \caption{Partial implementation of the regular operators}
  \label{fig:regular-operators-0}
\end{figure}
As a basis for further discussion, we exhibit a partial 
implementation in Figure~\ref{fig:regular-operators-0}.
This implementation has a number of deficiencies.
\begin{description}
\item[union] The output may contain duplicates. If
  \texttt{lx} is infinite, then no words from \texttt{ly} will ever be
  produced. This behavior violates the specification of set union
  because there may be elements in \texttt{ly} that never appear in
  \texttt{union lx ly}.

  If we restricted ourselves to finite lists, then replacing
  \texttt{++} with \texttt{Data.List.union} would be an appropriate
  implementation, but its worst-case time complexity is quadratic.
\item[concatenate] The output may contain duplicates. If \texttt{ly}
  is infinite, then only the first word in \texttt{lx} contributes to
  the output.

  For finite lists, an appropriate implementation would compose the
  raw product computation with \texttt{Data.List.nub} to remove
  duplicates. The worst-case complexity of \texttt{nub} is quadratic.
\item[intersect] The output contains no duplicates, if \texttt{lx}
  does not contain duplicates, either. If \texttt{ly} is infinite,
  then the resulting list may be partial because the \texttt{elem}
  operation may not terminate.

  For finite lists, this implementation is appropriate.
\item[star] The output may contain duplicates. If \texttt{lx} is
  infinite, then the generated language is just \texttt{T.empty : lx},
  so that many elements of \texttt{star lx} may not appear in the
  output.

  If \texttt{lx} is finite, then \texttt{star} can
  be implemented in a way that guarantees no duplication. However, to
  retain finiteness, we would have to impose an arbitrary limit on the
  size of the output.
\item[complement] In general there is no computable way to determine
  whether a word occurs in a lazy list \texttt{lx}. Hence, we have no
  good definition to propose.

  If \texttt{lx} is finite, then it is possible to
  enumerate its complement without repetitions. Again, to retain
  finiteness, we have to impose an arbitrary limit on the size
  of the output.
\end{description}
\begin{figure}[tp]
\begin{lstlisting}
module Examples.Finite where
import qualified Data.Text as T
import Data.List as L

limit :: Int
limit = 1024

union :: Lang -> Lang -> Lang
union lx ly = L.union lx ly

concatenate :: Lang -> Lang -> Lang
concatenate lx ly = L.nub [T.append wx wy | wx <- lx, wy <- ly ]

intersect :: Lang -> Lang -> Lang
intersect lx ly = [wx | wx <- lx, wx `elem` ly ]

star :: Lang -> Lang
star lx = take limit $ removeDuplicates $ concat lxs
  where
    lxs = [T.empty] : map (concatenate lx1) lxs
    lx1 = L.delete T.empty lx
    removeDuplicates [] = []
    removeDuplicates (w:ws) = w : removeDuplicates (filter (/=w) ws)

complement :: Alphabet -> Lang -> Lang
complement sigma lx = take limit (concat lsigmastar L.\\ lx) 
  where
    lsigmastar =
      [T.empty] : 
      map (\lsigmai -> concatMap (\la -> concatenate la lsigmai) lsigma1) lsigmastar
    lsigma1 = map (return . T.singleton) sigma
\end{lstlisting}
  \caption{Finite implementation of the regular operators}
  \label{fig:finite-regular-operators}
\end{figure}
Figure~\ref{fig:finite-regular-operators} contains an implementation
of a finite version of the generator module according to the preceding
discussion. The implementation of \texttt{star} follows the definition
of $U^*$ literally. It first recursively creates a list \texttt{lxs}
of the iterates $U_\bullet^i$ where
$U_\bullet = U \setminus \{\varepsilon\}$, concatenates all of
them\footnote{It is easy to see that $U^* = U_\bullet^*$.}, removes
the duplicates, and imposes the limit. Removing duplicates introduces
quadratic worst-case time complexity in the size of the output.

The implementation of \texttt{complement} generates the language
$\Sigma^*$ analogously to the construction of $U^*$ in
\texttt{star}, uses the list difference operator
\texttt{L.\textbackslash\textbackslash} to remove elements of
\texttt{lx}, and finally imposes the limit. Its worst-case run time is
$O(m\cdot n)$ where $m$ is the limit and $n = \code{length lx}$.

In summary, the naive approach in
Figure~\ref{fig:regular-operators-0} can generate infinite languages,
but has many drawbacks that lead to duplication and incompleteness
(words in the language are not enumerated). Moreover, the complement
is not computable for this approach.

The finite approach in Figure~\ref{fig:finite-regular-operators}
imposes an arbitrary limit on the number of generated words. This
limit can lead to omitting words in nonempty languages where $P (w\in
R) = 0$. Moreover, there are many places (in \texttt{union},
\texttt{concatenate}, and \texttt{star}) with quadratic worst-case
time complexity. 

At this point, the question is: Can we do better? Can we come up with
a generator that supports finite as well as infinite languages
efficiently without incurring extraneous quadratic behavior?


\subsection{Ordered Enumeration}
\label{sec:ordered-enumeration}
\begin{figure}[tp]
\begin{lstlisting}
union :: (Ord t) => [t] -> [t] -> [t]
union xs@(x:xs') ys@(y:ys') =
  case compare x y of
    EQ -> x : union xs' ys'
    LT -> x : union xs' ys
    GT -> y : union xs ys'
union xs ys = xs ++ ys
\end{lstlisting}

\begin{lstlisting}
intersect :: (Ord t) => [t] -> [t] -> [t]
intersect xs@(x:xs') ys@(y:ys') =
  case compare x y of
    EQ -> x : intersect xs' ys'
    LT -> intersect xs' ys
    GT -> intersect xs ys'
intersect xs ys = []
\end{lstlisting}

\begin{lstlisting}
difference :: (Ord t) => [t] -> [t] -> [t]
difference xs@(x:xs') ys@(y:ys') =
  case compare x y of
    EQ -> difference xs' ys'
    LT -> x : difference xs' ys
    GT -> difference xs ys'
difference xs ys = xs
\end{lstlisting}
  \caption{Union, intersection, and difference by merging lists}
  \label{fig:merging-lists}
\end{figure}

First, we concentrate on improving on the quadratic behavior. The key
to improve the complexity of union, intersection, and complement lies
in representing a language by a strictly increasingly sorted list.
In this case, the three operations can be implemented by variations of
the merge operation on lists as shown in
Figure~\ref{fig:merging-lists}.

The merge-based operations run in linear time on finite
lists. However, the operations in Figure~\ref{fig:merging-lists} are
incomplete on infinite lists. As 
an example of the incompleteness, consider the languages $U = a\cdot
(a+b)^*$ and the singleton language $V = \{b\}$ where $\Sigma = \{a, b\}$
with $a<b$, represented as strictly increasing lists, the infinite
list \code{lu} and the singleton list \code{lv}. The problem is that
the list \code{union lu lv} does not contain the word $b$; more
precisely, \code{T.singleton 'b' `elem` union lu lv} does not
terminate whereas \code{u `elem` union lu lv} yields \code{True} for
all \code{u} in \code{lu}. The source 
of the problem is that Haskell's standard ordering of lists and
\code{Text} is the \emph{lexicographic ordering}, which we call
$\le$. It relies on an underlying total ordering on $\Sigma$ and is
defined inductively:
\begin{mathpar}
  \inferrule{}{\varepsilon  \le v}
  
  \inferrule{u \le v}{au \le av}

  \inferrule{a < b}{au \le bv}
\end{mathpar}

This total ordering
is often used for $\Sigma^*$, but it has the property that
there are words $v<w$ such that there are infinitely many words $u$
with $v<u$ and $u<w$. For example, $v=a$, $w=b$, and $u\in U \setminus
\{a\}$, which explains the nonterminating behavior just exhibited.

Fortunately, there is another total ordering on words with better
properties. The
\emph{length-lexicographic ordering} is defined by $u \lleq 
v$ if $|u|<|v|$ or $|u|=|v|$ and $u\le v$ in the usual lexicographic
ordering (but only applied to words of the same length). Here is a definition in Haskell.
\begin{lstlisting}
llocompare :: T.Text -> T.Text -> Ordering
llocompare u v =
  case compare (T.length xs) (T.length ys) of
    EQ -> compare xs ys
    LT -> LT
    GT -> GT
\end{lstlisting}
This ordering has the additional advantage that it gives raise to a standard
enumeration of all words over a totally ordered alphabet as an order-preserving
bijective function from the natural numbers to $\Sigma^*$. Using this
bijection we can show that for each pair of words $v \lleq w$ there is only a finite
number of words $u$ such that $v \lleq u$ and $u \lleq w$. 

For the sake of simplicity, we assume from now on that \code{T.Text}
is ordered by \code{llocompare} and call the representation of a
language by a strictly increasing list in length-lexicographic order
its \emph{LLO representation}. 

With the LLO representation, the operations \code{union},
\code{intersect}, and \code{difference} run in linear time. If the input languages
are finite of size $m$ and $n$, respectively, then $O(m+n)$
comparisons, pattern matches, and cons operations are needed.
Moreover, the operations are complete in the sense that any element in
the output is sure to be detected by a terminating computation. 
It is easy to implement a version of \code{elem} that exploits the LLO ordering,
such that the element test is decidable for any infinite
language.



\subsubsection{Concatenation}
To implement concatenation, we are in the following situation. Given
two languages $U, V \subseteq \Sigma^*$ in LLO representation,
produce the LLO representation of $U \cdot V =  \{ u\cdot v \mid u\in
U, v\in V\}$. If we compute the product naively as in
Figure~\ref{fig:regular-operators-0}, then the output is not in LLO
form:\footnote{The example uses \code{String} for simplicity.}
\begin{verbatim}
λ> let lu = ["a", "ab"]
λ> let lv = ["", "b", "bb"]
λ> [ u++v | u <- lu, v <- lv ]
["a","ab","abb","ab","abb","abbb"]
\end{verbatim}
In fact, the output violates both constraints: it is not increasing
and it has duplicates.

Perhaps the following observation helps: for each $u\in U$, the LLO
representation of the language $u\cdot V$ can be trivially produced
because the list \code{[ u++v | v <- lv ]} is strictly
increasing. This observation motivates the following definition of
language concatenation (using \code{union} from Figure~\ref{fig:merging-lists}).
\begin{lstlisting}
concatenate' :: Lang -> Lang -> Lang
concatenate' lx ly =
  foldr union [] $ [[ T.append x y | y <- ly] | x <- lx]
\end{lstlisting}
This definition works fine as long as \code{lx} is finite. If it is
infinite, then the \code{foldr} creates an infinitely deep nest of
invocations of \code{union}, which do not make progress because
\code{union} is strict in both arguments.

At this point, the theory of formal languages can help. The notion of
a \emph{formal power series} has been invented to reason about and
compute with entire languages \cite{formal power series}. In full
generality, a formal power series is a mapping from $\Sigma^*$ into a
semiring $S$ and we write $\FPS{S}$ for the set of these
mappings. Formally, an element $r \in \FPS{S}$ is written as the
formal sum
\begin{align*}
  r &= \sum_{w \in \Sigma^*} (r,w) \cdot w
\end{align*}
where $(r,w) \in S$ is the coefficient of $w$ in $r$.
A popular candidate for this semiring is the boolean semiring $B$
because $\FPS{B}$ is isomorphic to the set of languages over
$\Sigma$. This isomorphism maps $L\subseteq\Sigma^*$ to its
characteristic series $r_L$ where $(r_L, w) = (w \in L)$.

The usual language operations have their counterparts on formal power
series. We consider just three of them where the ``additions'' and ``multiplications'' on the
right side of the definitions take place in the underlying semiring.
\begin{itemize}
\item Sum: $(r_1 + r_2, w) = (r_1, w) + (r_2, w)$ 
\item Product: $(r_1 \cdot r_2, w) = \sum_{uv=w} (r_1, u) (r_2,v)$
\item Hadamard product: $(r_1 \odot r_2, w) = (r_1, w) (r_2, w)$
\end{itemize}


\clearpage{}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
