\section{Motivation}
\label{sec:motivation}

Suppose someone implemented a clever algorithm for
regular expression matching, say  \code{match}. 
We want to use this implementation, but we also want to 
make sure it is largely bug free by subjecting it to extensive
testing.
So we need to come up with test cases and
implement a test oracle.


A test case consists of a regular expression \code{r} and an input
string \code{s}. If \code{matchOracle} is the test oracle, then
executing the test case means to execute \code{match r
  s} and check whether the result is correct by comparing it with
\code{matchOracle r s}. 

QuickCheck
\cite{DBLP:conf/icfp/ClaessenH00} is a library for property-based random testing, which is well suited for conducting such a test. Using 
QuickCheck, we would write a generator for regular expressions
and then use the generator for strings to generate many inputs for each
expression.

However, this approach has a
catch. Depending on the language of the regular expression, the
probability that a uniformly distributed random string is a member of the language can be 
severely skewed. As an example, consider the language $L = (ab)^*$ over the
alphabet $\Sigma = \{a, b\}$. Although $L$ contains infinitely many
words, the probability that a random word of
length $n$ is an element of $L$ is
\begin{center}
  \begin{tabular}{lcl}
    $\bullet$ $0$ if $n$ is odd and &\qquad& $\bullet$  $\frac{1}{2^n}$ if $n$ is even.
  \end{tabular}
\end{center}
The probability $p_n$ that a uniformly random word of length less than or equal to
$n$ is an element of $L$ is very small:
\begin{align*}
  p_n &= \frac{\lfloor n/2 \rfloor}{2^{n+1} - 1}
        \le \frac{n}{2^{n+2} - 2}
\end{align*}
The \textbf{density of $L$} is the probability $P (w\in L)$ of (uniformly) randomly
selecting a word in $L$, which is zero in the limit.


Hence, there are two problems.
\begin{enumerate}
\item How do we know whether the test oracle is correct, short of
  verifying it?
\item How do we generate relevant test cases, given
  that the density of  many regular languages is
  $0$ or $1$?
  % \footnote{Exercise for the
  %   interested reader:
  %   \begin{enumerate}
  %   \item Come up with a regular language $R$ such that $P(w\in R)$ is
  %     different from $0$ or $1$.
  %   \item Given a proper fraction $m/n$ (that is $n>0$ and $0\le m\le
  %     n$) define a regular language $R$ such that $P (w\in R) = m/n$.
  %   \end{enumerate}
  % }
\end{enumerate}


Wouldn't it be nice to have a systematic means
of generating words \textbf{inside} of $L$ and \textbf{outside} of
$L$? Such a generation algorithm would eliminate the oracle
and it would give us control over the number of test inputs
in the language and in the language's complement.

To construct such an algorithm we tackle the more general question of
generating the language of a regular expression extended with
operators for intersection ($\Rintersect{}{}$) and complement
($\Rcomplement{}$). This algorithm can generate the complement of
$L(r)$ by asking it to generate $L(\Rcomplement r)$.

\paragraph{Requirements}
\label{sec:requirements}

For the testing application, we propose some requirements for the generation algorithm to
avoid inefficiencies and spurious testing failures.
\begin{enumerate}
\item No repetitions in the output. %, as they would lead to repeated tests.
\item Output must not be partial.
\item Throttling output with respect to word
  length and number of generated words should be possible.
\item Generation should be compositional.
\item Reasonable efficiency.
\end{enumerate}

\section{Previous Work}
\subsection{Brief Intermezzo on Formal Languages}
\label{sec:research-question}

\begin{figure*}[!bt]
  \centering
  \begin{minipage}{1.0\linewidth}
  \begin{align*}
    r, s & \vspace{10cm}\ &\Lang{\_}=\quad &  &
                             \makebox[1em][l]{\code{data GRE sig}}\\
         & ::= \Rnull & \ltext{empty}
                        & \emptyset
                           &&\code{= Zero}\\
         & \mid \Rempty & \ltext{empty word}
                        & \{ \varepsilon \}
                           && \code{| One}\\
         & \mid (a \in \Sigma) & \ltext{singleton}
                        &  \{ a \}
                           && \code{| Atom sig} \\
         & \mid \Runion rs & \ltext{alternative}
                        &  \Lang{r} \cup \Lang{s}
                           && \code{| Or (GRE sig) (GRE sig)}\\
         & \mid \Rconcat rs & \ltext{concatenation}
                        &  \Lang r \cdot \Lang s
                           && \code{| Dot (GRE sig) (GRE sig)}\\
         & \mid \Rstar r & \ltext{Kleene star}
                        & \Lang r^* 
                           && \code{| Star (GRE sig)}\\
         & \mid \Rintersect rs & \ltext{intersection}
                        & \Lang r \cap \Lang s
                           && \code{| And (GRE sig) (GRE sig)}\\
         & \mid \Rcomplement r & \ltext{complement}
                        & \Sigma^* \setminus \Lang r
                           && \code{| Not (GRE sig)}
  \end{align*}
  \end{minipage}
  \caption{Generalized regular expressions: syntax, semantics, and Haskell encoding}
  \label{fig:generalized-regular-expressions}
\end{figure*}

Let $\Sigma$ be a finite set, the \textbf{alphabet}, totally ordered by $<$.  We write
$\Sigma^*$ for the set of finite words over $\Sigma$, which is defined
by $\bigcup_{i=0}^\infty \Sigma^i$ where $\Sigma^0 = \{\varepsilon\}$
and $\Sigma^{i+1} = \Sigma \times \Sigma^i$.
% \footnote{Equivalently
%   define $\Sigma^*$ inductively as the smallest set such that
%   $\varepsilon \in \Sigma^*$ and
%   $\forall a\in\Sigma, \forall w\in\Sigma^*, aw \in \Sigma^*$}
The
semantics of a regular expression, $\Lang r \subseteq \Sigma^*$, is a set of
words, defined in Figure~\ref{fig:generalized-regular-expressions}.
% It relies on standard definitions from the theory of formal languages.
We write
$\varepsilon$ for the empty word and $u\cdot v$ for the concatenation
of words $u, v \in \Sigma^*$. We write $|u|$ for the length of word
$u$. Unless otherwise specified, we use $a, b, c, \dots$ to range over
$\Sigma$ and $u, v, w, \dots$ to range over $\Sigma^*$.

If $U, V \subseteq \Sigma^*$ are
languages, then their concatenation (or product) is defined as $U\cdot
V = \{ u\cdot v \mid u\in U, v\in V\}$. We sometimes write $u\cdot V$
as an abbreviation for the product $\{u\}\cdot V$ with a singleton
language. The Kleene closure of a
language $U\subseteq \Sigma^*$ is defined as $U^* =
\bigcup_{i=0}^\infty U^i$ where $U^0 = \{\varepsilon\}$ and $U^{i+i} =
U \cdot U^i$. 

An extended regular expression
(Figure~\ref{fig:generalized-regular-expressions}) is built from the
regular operators empty set, empty word, singleton word consisting of
a single letter $a$ chosen from a finite alphabet $\Sigma$,
alternative, concatenation, and Kleene closure, intersection, and complement. The extra
operators 
do not add extra descriptive power as regular languages are closed
under intersection and complement \cite{DBLP:books/daglib/0011126},
but expressions can be more concise.


\subsection{McIlroy's Approach}
\label{sec:naive-approach}

\citet{DBLP:journals/jfp/McIlroy99} enumerates the words of a regular language as a
strictly increasingly ordered infinite stream using Haskell. A key insight is to use the
length-lexicographic ordering on words, which is defined by $u \lleq v$ if $|u|<|v|$ or
$|u|=|v|$ and $u\le v$ in the usual lexicographic ordering. Here is a definition in Haskell.\footnote{The type
  \lstinline{Data.Text.Text}, commonly imported as \lstinline{T.Text}, is an efficient
  string data type from the Haskell library. We only use \lstinline{T.empty} for the empty
  string, \lstinline{T.append} for string append, \lstinline{T.singleton} to create a
  single letter word, and \lstinline{T.length}.}
\begin{lstlisting}
llocompare :: T.Text -> T.Text -> Ordering
llocompare u v =
  case compare (T.length u) (T.length v) of
    EQ -> compare u v
    LT -> LT
    GT -> GT
\end{lstlisting}
This ordering gives raise to an
enumeration of all words over the alphabet $\Sigma$ via an order-preserving
bijection from the natural numbers to $\Sigma^*$. Using this
bijection we can show that for each pair of words $v \lleq w$ the
number of words $u$ such that $v \lleq u$ and $u \lleq w$ is finite. 


The Haskell code below defines a generator as a compositional function in terms of
the regular operations. 
\begin{lstlisting}
import qualified Data.Text as T

type Alphabet = [Char] -- ascendingly sorted
type Lang = [T.Text]   -- lazy stream of words

generate :: Alphabet -> GRE Char -> Lang
generate sigma r = gen r
  where
    gen Zero = []
    gen One  = [T.empty]
    gen (Atom t) = [T.singleton t]
    gen (Or r s) = union (gen r) (gen s)
    gen (Dot r s) = concatenate (gen r) (gen s)
    gen (Star r) = star (gen r)
    gen (And r s) = intersect (gen r) (gen s)
    gen (Not r) = complement sigma (gen r)
\end{lstlisting}

\begin{figure}[btp]
\begin{lstlisting}
module Examples.McIlroy where
import qualified Data.Text as T
import Examples.LLO (llocompare)

union :: Lang -> Lang -> Lang
union xs@(x:xs') ys@(y:ys') =
  case llocompare x y of
    EQ -> x : union xs' ys'
    LT -> x : union xs' ys
    GT -> y : union xs ys'
union xs ys = xs ++ ys

concatenate :: Lang -> Lang -> Lang
concatenate [] ly = []
concatenate lx [] = []
concatenate (x:xt) ly@(y:yt) =
  T.append x y : union (concatenate [x] yt) 
                       (concatenate xt ly)

star :: Lang -> Lang
star [] = [T.empty]
star lx@(x:xt) = if x == T.empty
  then star xt
  else T.empty : concatenate lx (star lx)
\end{lstlisting}
  \caption{McIlroy's implementation of regular operators}
  \label{fig:regular-operators-0}
\end{figure}
Figure~\ref{fig:regular-operators-0} contains McIlroy's implementation
of the regular operators. His definitions for \lstinline{concatenate}
and \lstinline{star} are more general, but that generality is not
needed for this application.

The \lstinline{union} operation is
implemented as a merge of two strictly increasing streams; the last
line only applies if one of the streams is empty. This definition is
productive and yields a strictly increasing stream.

The \lstinline{concatenate} operation is generic
sequence multiplication, which is productive. It yields a strictly
increasing stream because \lstinline{T.append x y} is the smallest
element in the product of \lstinline{lx} and \lstinline{ly} if
\lstinline{x} is smallest in \lstinline{lx} and \lstinline{y} is
smallest in \lstinline{ly}. If one of the input languages is infinite, then there is
a \lstinline{union} operation for each generated word.

The \lstinline{star} operation is defined by closure under concatenation. The definition
is productive and the output is strictly increasing as it is generated by
\lstinline{concatenate}.

This implementation is correct by construction as it closely follows the mathematical
definition of the operations. However, McIlroy readily admits in the paper it is very
inefficient.

\subsection{Extending McIlroy}
\label{sec:extending-mcilroy}

McIlroy's paper does not mention that the same representation of a
language enables the efficient implementation of
\lstinline{intersect}, \lstinline{difference}, and hence the
\lstinline{complement} operations!

\begin{figure}[tp]
\begin{lstlisting}
-- continuing module Examples.McIlroy

intersect :: Lang -> Lang -> Lang
intersect xs@(x:xs') ys@(y:ys') =
  case llocompare x y of
    EQ -> x : intersect xs' ys'
    LT -> intersect xs' ys
    GT -> intersect xs ys'
intersect xs ys = []

-- difference :: Lang -> Lang -> Lang
-- omitted for space reasons

complement :: Alphabet -> Lang -> Lang
complement sigma lx = difference lsigmastar lx
  where
    lsigmastar = star (map T.singleton sigma)
\end{lstlisting}
  \caption{Additional operations in McIlroy's framework}
  \label{fig:more-regular-operators}
\end{figure}
Figure~\ref{fig:more-regular-operators} shows that intersection and difference can be
implemented as simple variations of the \lstinline{union} operation. They run in linear
time on finite lists. Moreover, given a stream corresponding to $\Sigma^*$, which is easy
to define, and the difference operation, we obtain a definition of \lstinline{complement}.

At this point, we have an implementation of all 
operations, but concatenation (and hence star) is
inefficient. Observe further that neither \lstinline{intersect} nor
\lstinline{difference} are productive:
\lstinline{intersect} applied to two eventually disjoint infinite
streams is partial. For example, computing the intersection
$(ab)^* \cap (ba)^*$ yields a partial list, which starts with the
empty word, but never produces another word. As another example,
computing the difference $(aa)^* \setminus a^*$ never produces any
word.  Hence, the \lstinline{complement} operation is not
productive, either.

These definitions are not acceptable because they may produce
spurious test failures due to timeouts. Moreover, they make it
impossible to reliably gauge test inputs by length or number, 
because the generator may get stuck in an unproductive loop before
reaching the proposed limit.

\section{Generation by Cross Section}
\label{sec:gener-cross-sect}

We address the problems outlined with McIlroy's approach by switching to a
different \textbf{segment representation} for the generated language.
% It exploits some facts from formal language theory. 

Let $L\subseteq\Sigma^*$ be a language and $n$ be a natural
number. The \textbf{$n^{th}$ cross section of $L$} or
\textbf{$n^{th}$ segment of $L$} is $L_n := L \cap \Sigma^n$, the set of
words of length $n$ in $L$. As $L = \bigcup_{n\ge0} L_n$ we
define the \textbf{segment representation of $L$} by the
sequence of all segments, which we can write formally as a
power series\footnote{These power series are different
  from formal power series used in formal language theory
  \cite{DBLP:books/daglib/0067812,DBLP:books/sp/KuichS86}.}
\begin{gather*}
  L = \Sigma_{n=0}^\infty L_nx^n\text.
\end{gather*}

The language operations can be expressed on this representation by
standard operations on power series over semirings
$(\Power(\Sigma^*),\cup,\cdot)$ and $(\Power(\Sigma^*), \cup, \cap)$.
\begin{align}
  \label{eq:3}
  &\text{Sum:}
  & (U \cup V)_n &= U_n \cup V_n \\
  \label{eq:4}
  &\text{Hadamard product:}
  & (U \cap V)_n &= U_n \cap V_n \\
  \label{eq:1}
  &\text{Product:}
  & (U \cdot V)_n &= \bigcup_{i=0}^n U_i\cdot V_{n-i}
\end{align}

By applying
the usual spiel of representing a power series by its sequence of
coefficients, all operations become executable.
%
As the alphabet $\Sigma$ is finite, each segment $L_n$ is a finite set. Hence, the sum and
Hadamard product yield efficient definitions of language union and intersection. Due to
the change of representation, the intersection is productive: it produces the next segment
in finite time.

The Haskell representation of a language has the type
\begin{lstlisting}[numbers=none]
type SegLang = [[T.Text]]
\end{lstlisting}
where the outer list is assumed to be an infinite lazy stream and each inner list is
a finite, strictly increasing list of words of the same length. On
words of the same length, the length-lexicographic order is the same
as the lexicographic order.

The union, intersection, and difference operators on
\lstinline{SegLang} are defined according to Equations \eqref{eq:3} and
\eqref{eq:4}.
\begin{lstlisting}[numbers=none]
union = zipWith McIlroy.union
intersect = zipWith McIlroy.intersect
difference = zipWith McIlroy.difference
\end{lstlisting}

\begin{figure}[tp]
\begin{lstlisting}
concatenate :: SegLang -> SegLang -> SegLang
concatenate lx ly = collect 0
  where
    collect n =
      (foldr McIlroy.union []
         $ map (combine n) [0 .. n])
      : collect (n+1)
    combine n i =
      liftA2 T.append (lx !! i) (ly !! (n - i))
\end{lstlisting}
      % [T.append x y 
      % | x <- lx !! i, y <- ]
  \caption{Concatenation for segment representation}
  \label{fig:concatenate-with-segments}
\end{figure}

\paragraph{Concatenation}
As all
words in $U_i \cdot V_{n-i}$ in Equation~\eqref{eq:1} have length $n$, they belong to the
$n^{th}$ segment of the result. Both $U_i$ and
$V_{n-i}$ are strictly increasingly sorted, so the standard enumeration of pairs from
$U_i \times
V_{n-i}$ is sorted in the same way. Hence, our implementation of
\lstinline{concatenate} in Figure~\ref{fig:concatenate-with-segments}.  Function \code{combine} implements $U_i
\cdot V_{n-i}$ and  \lstinline{collect n} computes the stream of segments starting from
the $n^{th}$. Expression \lstinline{lx !! i} accesses the \lstinline{i}th element of
list \lstinline{lx}.  


\paragraph{Kleene Closure}
It is well known that $U^* = (U\setminus\{\varepsilon\})^*$. 
Hence, a simple calculation yields an
effective algorithm for computing the coefficients of the power series for $U^*$. 
\begin{align}
  \label{eq:2}
  &%\text{Star:}
  & (U^*)_0 &= 1
  & (U^*)_n &= (U \cdot U^*)_n = \bigcup_{i=1}^n U_i\cdot (U^*)_{n-i}
\end{align}
The key observation is that Equation~\eqref{eq:2} is a proper
inductive definition of the power series for $U^*$. It never touches $U_0$ and the union
only touches the coefficients $(U^*)_{n-1}$ down to $(U^*)_0$. Hence, $(U^*)_n$ is well
defined as it only relies on $U$ and previously computed indexes!

\begin{figure}[tp]
\begin{lstlisting}
star :: SegLang -> SegLang
star lx = lstar
  where
    lstar = [T.empty] : collect 1
    collect n =
      (foldr union [] 
         $ map (combine n) [1 .. n])
      : collect (n + 1)
    combine n i =
      liftA2 T.append (lx !! i) (lstar !! (n - i))
\end{lstlisting}
    % combine n i =
    %   [T.append x y 
    %   | x <- lx !! i, y <- lstar !! (n - i)]
  \caption{Kleene closure for segment representation}
  \label{fig:star-with-segments}
\end{figure}
Figure~\ref{fig:star-with-segments} contains the resulting implementation of Kleene closure.
The \code{collect} and \code{combine} functions are almost
identical, \lstinline{lstar} is defined recursively, but this recursion is well-founded as
we just argued. 

\paragraph{Complement}
\begin{figure}[tp]
\begin{lstlisting}
complement :: Alphabet -> SegLang -> SegLang
complement sigma lx = difference lsigmastar lx
  where
    lsigmastar =
      [T.empty] : map extend lsigmastar
    extend lsigmai =
      [T.cons a w | a <- sigma, w <- lsigmai]
\end{lstlisting}
  \caption{Complementation for the segment representation}
  \label{fig:llo-complement}
\end{figure}
To define the \lstinline{complement} operation, all we need is to define the segment
representation of $\Sigma^*$, which can be done analogously to computing the closure, and
apply the \code{difference} operator. Figure~\ref{fig:llo-complement} puts it all together.

\paragraph{Discussion}\label{sec:motivation-discussion}
What have we gained?

Productivity: We can generate productive segment
representations from all extended regular expressions. The implementation of each
operation is guided by corresponding operations on power series.

Easy Gauging: To restrict the generated segmented output, say \code{segs}, to words of
length less than a given 
bound \code{n}, all we need to do is \code{concat (take n segs)}. The result is
a finite list of words. In contrast, such filtering is not effective
for the LLO representation where
\lstinline{takeWhile (\w -> T.length w <  n) llo} may yield a partial list.


There is a catch: As the output is always an infinite list, we loose the
information that a language is finite. The advantange of this choice is simplicity: index
accesses into the languages \code{lx} and \code{ly} are always defined. 
However, the list index operation used in the \lstinline{combine} function requires time
linear in its index argument, which may be inefficient.  
The next section discusses ways to address these shortcomings.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
