\section{Related Work}
\label{sec:related-work}

\subsubsection*{Regular Language Generation}

\citet{DBLP:journals/actaC/Makinen97} describes a method to enumerate
the words of a regular language $L$ in length-lexicographic
ordering. It relies on the regular language being defined by a
deterministic finite automaton. To generate words up to length $n$,
this method requires to precompute, for each $i\le n$, the
lexicographically minimal and maximal word of length $i$ in $L$. This
precomputation takes time $O(n)$.

The actual enumeration starts with the precomputed minimal word of
length $n$ and repeatedly computes the lexicographically next word
until it reaches the maximal word of length $n$. Each such step requires time $O(n)$. 

The same approach can be used for enumerating the language of certain
(prefix-free, length complete) context-free grammars, too.

Compared to our approach, M{\"{a}}kinen requires a deterministic
finite automaton, which can be obtained from a regular expression in
worst-case exponential time. Complementation is not mentioned, but it
can obviously be handled. M{\"{a}}kinen would give rise to a
productive definition by segments because the computation of minimal
and maximal words could be done incrementally, but which is not mentioned
in the paper.

\citet{DBLP:journals/jfp/McIlroy04} implements the enumeration of all
strings of a regular language in Haskell. He develops two approaches,
one based on interpreting regular expressions, the other (unrelated to
ours) using a shallow embedding of nondeterministic finite
automata. The first approach is inspired by an earlier note by Misra
\cite{misra11:_enumer_strin_regul_expres} and uses operators based on
a length-lexicographically increasing list representation similar to
our first proposal.

The implementation of union is identical to ours, but intersection and
difference operations are not considered and hence complementation is
not considered, either. The implementation of concatenation is the
generic multiplication operation for sequences / power series
\cite{DBLP:journals/jfp/McIlroy99} instantiated for the semiring
of union and concatenation of languages. Unlike our implementation, the generic 
implementation does not take advantage of the fact that many
intermediate results can be generated in the correct ordering and hence
requires many more union operations (one for each output string versus
one for each length between $0$ and $n$ where $n$ is the length of
the output string).  Moreover, the generation method is reported to
be very inefficient and thus not suitable for generating test inputs
at a large scale.

\citet{DBLP:conf/wia/LeeS04} discuss enumerating regular expressions
and their languages. Despite the title, this work is unrelated
because it aims to find bounds on the number of languages that can be
represented with regular expressions and automata of a certain size.

\citet{DBLP:journals/tcs/AckermanS09} improve on M{\"{a}}kinen's
algorithm by working directly on a nondeterministic finite
automaton. They critize his complexity analysis, which assumes unit
cost for comparison and concatenation operations on words and does not
account for the size $s$ of the automaton, and obtain $O (s^2n^2)$ for
the computation of minimal words.


\subsubsection*{Language Generation}
Some authors discuss the generation of test sentences from grammars for
exercising compilers
(e.g., \cite{DBLP:conf/cisse/ParachaF08,DBLP:conf/compsac/ZhengW09}
for some recent work). This
line of work goes back to Purdom's sentence generator for testing
parsers \cite{purdom72:_senten_gener_testin_parser}, which creates
sentences from a context-free grammar using each production at least
once.

Compared to our generator, the previous work starts from context-free
languages and aims at testing the apparatus behind the parser,
rather than the parser itself. Hence, it focuses on generating
positive examples, whereas we are also interested in counterexamples.

Grammar Testing~\cite{DBLP:conf/fase/Lammel01} aims to
identify and correct errors in a grammar by exercising it on example
sentences. The purpose is to recover ``lost'' grammars of programming
languages effectively.
Other work \cite{DBLP:conf/compsac/LiJLG04} also targets
testing the grammar, rather than the parser.

\subsubsection*{Test Data Generation}

Since the introduction of
QuickCheck~\cite{DBLP:conf/icfp/ClaessenH00}, property testing and
test-data generation has been used successfully in a wide variety of
contexts.  In property testing, input data for the function to test is
described via a set of combinators while the actual generation is
driven by a pseudo-random number generator. One difficulty of this
approach is to find the correct distribution of inputs that will
generate challenging test cases. This problem already arises with
recursive data types, but it is even more pronounced when generating
test inputs for regular expressions because, as explained in
\cref{sec:motivation}, many languages have a density of zero, which
means that a randomly generated word almost never belongs to the
langer.  Generating random \emph{regular expressions} is much
easier. We can thus combine property testing to generate regular
expressions and then apply our language generator to generate targeted
positive and negative input for these randomly generated regular
expressions.

\citet{DBLP:journals/jfp/NewFFM17} are concerned with the enumeration
of elements of various data structures. Their approach is
complementary to test-data generators. They exploit bijections between
natural numbers and the data domain and develop a quality criterion
for data generators based on a notion of fairness. It would be
interesting to investigate the connection between their enumeration
strategies and a direct representation of formal power series.

Crowbar~\cite{crowbar} is a library that combines property testing
with fuzzing.  In QuickCheck, the generation is driven by a random
number generator. Crowbar replaces this generator by
\texttt{afl-fuzz}~\cite{afl}. Afl is a fuzzer that relies on runtime
instrumentation to provide good code coverage, thus eliminating the
need to specify the distribution of random generators.  This approach,
however, is not sufficient to generate both regular expressions and
inputs, as we would still require an oracle. Our language generator
could allow to easily fuzz regular expression parsers.


% \subsubsection*{Testing Program Generators}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
